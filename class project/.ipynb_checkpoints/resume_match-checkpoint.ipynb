{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "kvfKJiFJPkHB",
    "outputId": "d9797782-3a50-464f-fb42-79aedc863e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "8G9Yj7TCHHCB",
    "outputId": "cab1db0a-ebb8-4d5b-f6b8-cbbc7afb601e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        jianfei zhao jeff zhao jz nyuedu wwwlinkedinco...\n",
      "1        future make join honeywell become member globa...\n",
      "2        data scientist sequencing bioinformatics roche...\n",
      "3        data scientist professional needed walmart sun...\n",
      "4        inficon growing global leading provider innova...\n",
      "                               ...                        \n",
      "18774    team lead solution architect provide venue exp...\n",
      "18777    principal system solutions architectcompany ov...\n",
      "18778    client permanent opportunity preferred locatio...\n",
      "18779    honeywell equal opportunity employer qualified...\n",
      "18780    eliassen group provides strategic talent solut...\n",
      "Name: desc_clean, Length: 14791, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# load data\n",
    "#df = pd.read_csv('./jobs_small.csv', encoding=\"latin-1\")\n",
    "df = pd.read_csv('./jobs.csv', encoding=\"utf-8\")\n",
    "#print(df.head())\n",
    "\n",
    "# text preprocessing\n",
    "REPLACE_BY_SPACE_RE = re.compile('[#+_/(){}!^?<>\"''*\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "match_regex = re.compile('\\d+')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# data cleaning\n",
    "def clean_text(text):\n",
    "    # change to lower-csae\n",
    "    text = str(text).lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    # remove BAD_SYMBOLS_RE\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = match_regex.sub('', text)\n",
    "    # drop the stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    return text\n",
    "\n",
    "# read and clean the resume file\n",
    "f = open('./resume.txt', 'r')          ############# change resume here ####################\n",
    "text = f.read()\n",
    "text = clean_text(text)\n",
    "\n",
    "# clean the desc field\n",
    "df['desc_clean'] = df['description'].apply(clean_text)\n",
    "df.drop(columns=['description', 'id'], inplace=True)\n",
    "df.loc[0] = ['resume', 0, 0, 0, text]\n",
    "\n",
    "for i in range(len(df)):\n",
    "  try:\n",
    "    if df['desc_clean'][i]=='nan' or df['desc_clean'][i]=='' or len(df['desc_clean'][i]) < 100:\n",
    "      df.drop(labels=i, inplace=True)\n",
    "  except:\n",
    "    continue\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['id'] = [i for i in range(len(df))]\n",
    "print(df['desc_clean'])\n",
    "df.to_csv('./jobs_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "6x0T-83svJ_9",
    "outputId": "98de748a-8194-4b8c-c933-fb7898afe061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of jobs： 14791\n",
      "+------+---+---+--------------------+\n",
      "|   job|id1|id2|          similarity|\n",
      "+------+---+---+--------------------+\n",
      "|resume|  0|  0|  1.0000000000000016|\n",
      "|resume|  0|  1| 0.01043801713733717|\n",
      "|resume|  0|  2|7.405503588392814E-4|\n",
      "|resume|  0|  3|0.007065724550965595|\n",
      "|resume|  0|  4|   0.023492545109239|\n",
      "|resume|  0|  5|0.040844218054418825|\n",
      "|resume|  0|  6|0.004198557619658468|\n",
      "|resume|  0|  7|0.013267752098056557|\n",
      "|resume|  0|  8|0.019068246791674657|\n",
      "|resume|  0|  9|0.009293467462362679|\n",
      "+------+---+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "#from pyspark.ml.feature import NGram\n",
    "\n",
    "spark=SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('tfidf_app') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# load data\n",
    "df0 = spark.read.csv(\"./jobs_clean.csv\", header=True, multiLine=True, inferSchema=True)\n",
    "#df0.show()\n",
    "print('The number of jobs：',df0.count())\n",
    "\n",
    "# split the desc field\n",
    "tokenizer = Tokenizer(inputCol='desc_clean', outputCol='desc_words')\n",
    "df = tokenizer.transform(df0)\n",
    "#df.show()\n",
    "#df.select('desc_words').show(10)\n",
    "\n",
    "# compute TF-IDF\n",
    "hashingTF = HashingTF(inputCol='desc_words', outputCol='desc_words_tf')\n",
    "tf = hashingTF.transform(df).cache()\n",
    "idf = IDF(inputCol='desc_words_tf', outputCol='desc_words_tfidf').fit(tf)\n",
    "tfidf = idf.transform(tf).cache()\n",
    "#print('tfidf for each job:', tfidf.select('desc_words_tfidf').show(10,truncate=False))\n",
    "\n",
    "# data normalization\n",
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = Normalizer(inputCol=\"desc_words_tfidf\", outputCol=\"norm\")\n",
    "tfidf = normalizer.transform(tfidf)\n",
    "#tfidf.select(\"id\", \"norm\").show(6)\n",
    "\n",
    "# compute similarity between jobs and resume\n",
    "import pyspark.sql.functions as psf \n",
    "from pyspark.sql.types import DoubleType\n",
    "dot_udf = psf.udf(lambda x,y: float(x.dot(y)), DoubleType()) # define dot-product function\n",
    "tfidf = tfidf.alias(\"a1\").join(tfidf.alias(\"a2\"), psf.col(\"a1.id\") == 0)\\\n",
    "        .select(\n",
    "            psf.col(\"a1.job\"),\n",
    "            psf.col(\"a1.id\").alias(\"id1\"), \n",
    "            psf.col(\"a2.id\").alias(\"id2\"), \n",
    "            dot_udf(\"a1.norm\", \"a2.norm\").alias(\"similarity\"))\n",
    "tfidf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "EXO-Isbk6Uj8",
    "outputId": "5e457ac1-195b-457f-d5d0-ce06c52dfe9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 matched jobs:\n",
      "+--------------------+--------------------+--------------------+-------------------+\n",
      "|                 job|             company|            location|         similarity|\n",
      "+--------------------+--------------------+--------------------+-------------------+\n",
      "|Machine Learning ...|Southwest Researc...|  San Antonio, Texas|0.08116147399903528|\n",
      "|       FPGA Engineer|Microchip Technology|San Jose, California|0.08064671429779627|\n",
      "|       FPGA Engineer|Lam Research Corp...|Fremont, Californ...|0.08037405195916836|\n",
      "|        DSP engineer|Lam Research Corp...|Fremont, Californ...|0.08037405195916836|\n",
      "|       FPGA Engineer|            Randstad|Ashaway, Rhode Is...|0.07606167591026433|\n",
      "|Embedded Systems ...|Southwest Researc...|  San Antonio, Texas|  0.071527836903023|\n",
      "|        DSP engineer|    ON Semiconductor|San Jose, California|0.06983257516394467|\n",
      "|       FPGA Engineer|Odyssey Systems C...|Lexington, Massac...|0.06794424029819622|\n",
      "|Embedded Systems ...|Odyssey Systems C...|Lexington, Massac...|0.06794424029819622|\n",
      "|        DSP engineer|Odyssey Systems C...|Lexington, Massac...|0.06794424029819622|\n",
      "|        ARM engineer|Odyssey Systems C...|Lexington, Massac...|0.06794424029819622|\n",
      "|Circuit Design En...|Randstad Technolo...|Ashaway, Rhode Is...|0.06712068324775063|\n",
      "|       FPGA Engineer|Randstad Technolo...|Ashaway, Rhode Is...|0.06712068324775063|\n",
      "|       FPGA Engineer|            Dynetics| Huntsville, Alabama|0.06575373417683203|\n",
      "|Machine Learning ...|Southwest Researc...|  San Antonio, Texas|0.06496953463692742|\n",
      "|computer vision e...|Southwest Researc...|  San Antonio, Texas|0.06496953463692742|\n",
      "|computer vision e...|         CyberCoders|Irvine, Californi...|0.06496923964857998|\n",
      "|Python Software E...|         CyberCoders|Irvine, Californi...|0.06496923964857998|\n",
      "|Machine Learning ...|Southwest Researc...|  San Antonio, Texas| 0.0647745018675982|\n",
      "|computer vision e...|Southwest Researc...|  San Antonio, Texas| 0.0647745018675982|\n",
      "+--------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show Top-20 matched jobs\n",
    "match = tfidf.where('id1 = 0').sort('similarity', ascending=False).where('id2 > 0')\n",
    "top_match = match.limit(20)\n",
    "print('Top 20 matched jobs:')\n",
    "df0.alias(\"a1\").join(top_match.alias(\"a2\"), psf.col(\"a1.id\") == psf.col(\"a2.id2\"))\\\n",
    "    .select(psf.col(\"a1.job\"), \"a1.company\", \"a1.location\", \"a2.similarity\")\\\n",
    "    .sort('similarity', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9VpHzNJigQE"
   },
   "outputs": [],
   "source": [
    "match = df0.alias(\"a1\").join(match.alias(\"a2\"), psf.col(\"a1.id\") == psf.col(\"a2.id2\"))\\\n",
    "    .select(psf.col(\"a1.job\"), \"a1.company\", \"a1.location\", \"a2.similarity\")\\\n",
    "    .sort('similarity', ascending=False)\n",
    "\n",
    "# create SQL table\n",
    "match.createOrReplaceTempView(\"match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "eSfKy7g3n3ez",
    "outputId": "50bfe195-9a75-4d6a-ebf6-0cfc91d5413f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                 job|             company|            location|          similarity|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Telecommunication...|      Clarapath Inc.|New York City, Ne...| 0.03648633647025688|\n",
      "|       FPGA Engineer|      Clarapath Inc.|New York City, Ne...| 0.03648633647025688|\n",
      "|              python|    Case Interactive|New York City, Ne...|0.030861421430990247|\n",
      "|Python Software E...|    Case Interactive|New York City, Ne...|0.027351413502308866|\n",
      "|JavaScript Developer|    Case Interactive|New York City, Ne...|0.027351413502308866|\n",
      "|Telecommunication...|      Clarapath Inc.|New York City, Ne...|0.023265618129192603|\n",
      "|       web developer|      Clarapath Inc.|New York City, Ne...|0.023265618129192603|\n",
      "|Machine Learning ...|   Zeta Global Corp.|New York City, Ne...|0.020032484350870673|\n",
      "|  software-developer|   Zeta Global Corp.|New York City, Ne...|0.020032484350870673|\n",
      "|database administ...|Business Informat...|New York City, Ne...| 0.01936572883875255|\n",
      "|          IT manager|  Cloud Destinations|New York City, Ne...|0.017804185749178407|\n",
      "|   Android Developer|            Data Inc|New York City, Ne...|0.017239188559040615|\n",
      "|   Database Engineer|           Hsgi Inc.|New York City, Ne...|0.016500187984202594|\n",
      "|Java Software Eng...|            Data Inc|New York City, Ne...| 0.01628034228468379|\n",
      "|      Spark Engineer|        Apex Systems|New York City, Ne...|0.014320135464761885|\n",
      "|           Architect|          AlfaPeople|New York City, Ne...|0.014021506524024011|\n",
      "|   Database Engineer|          AlfaPeople|New York City, Ne...|0.014021506524024011|\n",
      "|Java Software Eng...|            Data Inc|New York City, Ne...|0.013767071830939503|\n",
      "|      Spark Engineer|            Data Inc|New York City, Ne...|0.013767071830939503|\n",
      "|   Node js developer|Foote, Cone & Bel...|New York City, Ne...|0.012370119287410924|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start SQL query\n",
    "\n",
    "# select jobs in specific location\n",
    "df = spark.sql(\"SELECT * FROM match WHERE location like 'New York City%'\")\n",
    "#df = spark.sql(\"SELECT * FROM match WHERE location like 'San Francisco%'\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "CLmUQOV-wD2u",
    "outputId": "08c6f728-693e-4184-f512-c6e598fce563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+\n",
      "|          job|             company|            location|          similarity|\n",
      "+-------------+--------------------+--------------------+--------------------+\n",
      "|FPGA Engineer|Microchip Technology|San Jose, California| 0.08064671429779627|\n",
      "|FPGA Engineer|Lam Research Corp...|Fremont, Californ...| 0.08037405195916836|\n",
      "|FPGA Engineer|            Randstad|Ashaway, Rhode Is...| 0.07606167591026433|\n",
      "|FPGA Engineer|Odyssey Systems C...|Lexington, Massac...| 0.06794424029819622|\n",
      "|FPGA Engineer|Randstad Technolo...|Ashaway, Rhode Is...| 0.06712068324775063|\n",
      "|FPGA Engineer|            Dynetics| Huntsville, Alabama| 0.06575373417683203|\n",
      "|FPGA Engineer|Southwest Researc...|  San Antonio, Texas| 0.06334817461660834|\n",
      "|FPGA Engineer|              Leidos| Arlington, Virginia| 0.06330316740158387|\n",
      "|FPGA Engineer|Ageatia Global So...|   Palm Bay, Florida|0.062102049341652796|\n",
      "|FPGA Engineer|Ageatia Global So...|San Leandro, Cali...|0.062075617354896216|\n",
      "|FPGA Engineer|Radiance Technolo...|   Ruston, Louisiana|0.061099561454726954|\n",
      "|FPGA Engineer|         CyberCoders|Santa Clara, Cali...|0.060283272717708225|\n",
      "|FPGA Engineer|Omnivision Techno...|Santa Clara, Cali...|0.060240627615715685|\n",
      "|FPGA Engineer|         CyberCoders|San Diego, Califo...| 0.06002196451203928|\n",
      "|FPGA Engineer|Galaxy Technology...|Chicago, Illinois...|0.059666718972044216|\n",
      "|FPGA Engineer|Artech Informatio...|San Jose, California| 0.05944409954214891|\n",
      "|FPGA Engineer|Randstad Technolo...|Ashaway, Rhode Is...| 0.05832907686355402|\n",
      "|FPGA Engineer| Minuteman Group LLC|Lexington, Massac...| 0.05784570774329104|\n",
      "|FPGA Engineer|              Belcan|        Dayton, Ohio| 0.05736064182339971|\n",
      "|FPGA Engineer|Rincon Research Corp|     Tucson, Arizona| 0.05685918296027039|\n",
      "+-------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select specific jobs\n",
    "#df = spark.sql(\"SELECT * FROM match where job = 'computer vision engineer'\")\n",
    "df = spark.sql(\"SELECT * FROM match where job = 'FPGA Engineer'\")\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "resume_match.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
